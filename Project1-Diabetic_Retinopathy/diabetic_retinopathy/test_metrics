from evaluation.metrics import ConfusionMatrix, Accuracy, Sensitivity, Specificity, F1_Score, ROC_AUC
import tensorflow as tf

y_true = tf.constant([1,1,0,1,1,1], dtype=tf.float32)
y_pred = tf.constant([1,0,1,0,1,1], dtype=tf.float32)

#Confusion Matrix
a=ConfusionMatrix()
a.update_state(y_true,y_pred)
conf_mat=a.result().numpy()
print(conf_mat)

#Accuracy
b=Accuracy()
b.update_state(y_true,y_pred)
acc=b.result().numpy()
print(acc)

#Sensitivity
c=Sensitivity()
c.update_state(y_true,y_pred)
sens=c.result().numpy()
print(sens)

#Specificity
d=Specificity()
d.update_state(y_true,y_pred)
spec=d.result().numpy()
print(spec)

#F1_Score
k=F1_Score()
k.update_state(y_true,y_pred)
f1_score=d.result().numpy()
print(f1_score)

# ROC/AUC Score
l=ROC_AUC()
l.update_state(y_true,y_pred)
roc_auc=l.result().numpy()
print(roc_auc)
